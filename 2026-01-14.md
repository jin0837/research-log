# Learning Log – DL最終課題 総括（2026-01-14）

## 位置づけ

本ログは、松尾研ディープラーニング講座・最終課題について  
**成果物の提出をもって一区切りとし、そこから得られた学びと今後の方針を整理するための総括**である。

精度や順位ではなく、  
「何を理解し、何が課題として残ったか」を明確にすることを目的とする。

---

## 最終課題で取り組んだこと（要約）

- 画像系タスクに対し CNN ベースのモデルを構築
- 精度向上を目的として ResNet50 を導入
- class imbalance が強い状況下で学習挙動を観察

---

## 直面した問題

### 1. 高性能モデル導入によるブラックボックス化

- ResNet50 導入後、
  - なぜ精度が上がらないのか
  - どこで学習が破綻しているのか
  を自分の言葉で説明できなくなった。

→ **モデルを使っているが、理解していない状態**に陥った。

---

### 2. 精度改善＝モデル変更という短絡

- 精度が出ない原因を
  - 損失関数
  - 勾配の流れ
  - データ分布
  ではなく、
  - 「もっと強いモデルが必要」
  と解釈してしまっていた。

---

## 最大の学び

### 学び①：精度は「設計の結果」であり「運」ではない

Softmax + Cross Entropy における

\[
dx = \frac{y - t}{N}
\]

という勾配の形を理解したことで、

- class imbalance が  
  **データの問題ではなく、勾配設計の問題として扱える**
- 精度は偶然ではなく、  
  **どの誤差をどれだけ強く学習させるかの意思決定の結果**

であると理解した。

---

### 学び②：分からない状態に気づけることが研究の第一歩

- 「何をしているか分からない」状態で改善を続けるのは研究ではない
- いったんシンプルなモデルに戻す判断は後退ではなく、
  **再現性と理解を取り戻すための前進**

---

### 学び③：DLは目的ではなく観測装置

- DLを「精度を出す魔法」として扱うのではなく、
- 現象を定量的に切り出し、仮説検証を高速化するための道具として使う

という研究者視点が明確になった。

---

## 今後の方針

### 1. DL学習の方針

- 高度なモデルを増やす前に、
  - 勾配
  - 損失関数
  - 学習挙動
  を説明できる状態を最優先する
- 『0から作るDeep Learning』の理解を軸に、
  **「自分で書ける・追える」実装を積み重ねる**

---

### 2. Kaggleの位置づけ

- 順位を追う場ではなく、
  - 仮説 → 実装 → 失敗 → 言語化
  を回すための実験場として使う
- class imbalance や loss 設計を意識した実験を継続する

---

### 3. 研究への接続

- Wet研究で得られる曖昧な現象を、
  DLを用いて「観測可能な量」に落とす
- 分子生物学 × AI という文脈において、
  **DLは主役ではなく、思考を補助する装置**

として扱う。

---

## 総括

本最終課題は、

- 精度という結果以上に、
- 自分が「何を理解していて、何を理解していないか」を明確にする

という点で非常に価値のある経験だった。

今後は  
**理解できるモデルで、理解できる仮説検証を積み重ねる**ことを最優先に進める。
